{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Week 01 · Advanced RAG with Services\n",
        "\n",
        "**Objective**: Build RAG, CAG, and CRAG using service layer.\n",
        "\n",
        "**Architecture**: Uses `RAGService`, `CAGService`, `CRAGService` from `context_engineering.application.chat_service`\n",
        "\n",
        "**Provider Support**: Uses OpenRouter unified API for multi-provider LLM access (GPT-4o, Claude, Gemini, etc.) or direct OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "#  Setup & Installations\n",
        "import sys\n",
        "\n",
        "# if \"google.colab\" in sys.modules or True:\n",
        "#     print(\" Installing required packages...\")\n",
        "#     %pip install -q langchain-core>=0.1.0 langchain-openai>=0.0.5 langchain-community>=0.0.20 chromadb>=0.4.0 python-dotenv>=1.0.0\n",
        "\n",
        "# print(\" Packages ready\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\Sahas Induwara\\.conda\\envs\\sahas\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n",
            " Environment loaded\n",
            " Provider: OpenRouter\n",
            " Project root: d:\\Courses\\_Zuu Crew\\AI Engineer Essentials\\Programming\\Context Engineering\n"
          ]
        }
      ],
      "source": [
        "#  Imports & Environment Setup\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "from pathlib import Path\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Add project root to path\n",
        "project_root = Path.cwd().parent\n",
        "sys.path.insert(0, str(project_root / \"src\"))\n",
        "\n",
        "# Load environment\n",
        "load_dotenv(project_root / \".env\")\n",
        "\n",
        "# Check for API key (OpenRouter preferred, OpenAI as fallback)\n",
        "openrouter_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
        "openai_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "if not openrouter_key and not openai_key:\n",
        "    raise EnvironmentError(\n",
        "        \"   No API key found!\\n\"\n",
        "        \"   Add OPENROUTER_API_KEY (recommended) or OPENAI_API_KEY to .env\"\n",
        "    )\n",
        "\n",
        "# Load configuration\n",
        "from context_engineering.config import (\n",
        "    VECTOR_DIR, CACHE_DIR, TOP_K_RESULTS,\n",
        "    CHAT_MODEL, EMBEDDING_MODEL, PROVIDER\n",
        ")\n",
        "\n",
        "provider = \"OpenRouter\" if openrouter_key else \"OpenAI\"\n",
        "print(\" Environment loaded\")\n",
        "print(f\" Provider: {provider}\")\n",
        "print(f\" Project root: {project_root}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import Chat Services\n",
        "\n",
        "Using RAG/CAG/CRAG services from application layer (NOT defined here!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Chat services loaded from service layer\n",
            " Location: context_engineering.application.chat_service\n",
            "\n",
            " Available services:\n",
            "   1. RAGService   - Standard RAG with modern LCEL\n",
            "   2. CAGService   - Cache-Augmented Generation (semantic)\n",
            "   3. CRAGService  - Corrective RAG with confidence scoring\n",
            "   4. CAGCache     - Semantic cache (FAQs + History)\n"
          ]
        }
      ],
      "source": [
        "#  Import Chat Services\n",
        "from context_engineering.application.chat_service import (\n",
        "    RAGService,\n",
        "    CAGService,\n",
        "    CRAGService,\n",
        "    CAGCache\n",
        ")\n",
        "\n",
        "print(\" Chat services loaded from service layer\")\n",
        "print(\" Location: context_engineering.application.chat_service\")\n",
        "print(\"\\n Available services:\")\n",
        "print(\"   1. RAGService   - Standard RAG with modern LCEL\")\n",
        "print(\"   2. CAGService   - Cache-Augmented Generation (semantic)\")\n",
        "print(\"   3. CRAGService  - Corrective RAG with confidence scoring\")\n",
        "print(\"   4. CAGCache     - Semantic cache (FAQs + History)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " LLM initialized: openai/gpt-4o-mini\n",
            " Embeddings initialized: openai/text-embedding-3-large\n",
            " Provider: openrouter\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Sahas Induwara\\AppData\\Local\\Temp\\ipykernel_45532\\3102933705.py:20: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the `langchain-chroma package and should be used instead. To use it run `pip install -U `langchain-chroma` and import as `from `langchain_chroma import Chroma``.\n",
            "  vectorstore = Chroma(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Connected to vector store\n",
            " Collection size: 875 vectors\n"
          ]
        }
      ],
      "source": [
        "#  Connect to Vector Store & Initialize LLM\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from context_engineering.infrastructure.llm_providers import (\n",
        "    get_default_embeddings,\n",
        "    get_chat_llm\n",
        ")\n",
        "\n",
        "# Initialize using service factories (supports OpenRouter + multi-provider)\n",
        "embeddings = get_default_embeddings()\n",
        "llm = get_chat_llm(temperature=0)\n",
        "\n",
        "print(f\" LLM initialized: {CHAT_MODEL}\")\n",
        "print(f\" Embeddings initialized: {EMBEDDING_MODEL}\")\n",
        "print(f\" Provider: {PROVIDER}\")\n",
        "\n",
        "# Connect to vector store\n",
        "if not VECTOR_DIR.exists():\n",
        "    raise FileNotFoundError(f\" Run 02_chunk_and_embed.ipynb first\")\n",
        "\n",
        "vectorstore = Chroma(\n",
        "    persist_directory=str(VECTOR_DIR),\n",
        "    embedding_function=embeddings,\n",
        "    collection_name=\"nawaloka\"\n",
        ")\n",
        "\n",
        "# Create retriever\n",
        "retriever = vectorstore.as_retriever(\n",
        "    search_type=\"similarity\",\n",
        "    search_kwargs={\"k\": TOP_K_RESULTS}\n",
        ")\n",
        "\n",
        "print(f\" Connected to vector store\")\n",
        "print(f\" Collection size: {vectorstore._collection.count()} vectors\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# 1️ Standard RAG with Service"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " RAGService initialized\n",
            " Retrieval: top-4 documents\n"
          ]
        }
      ],
      "source": [
        "#  Initialize RAG Service\n",
        "rag_service = RAGService(\n",
        "    retriever=retriever,\n",
        "    llm=llm,\n",
        "    k=TOP_K_RESULTS\n",
        ")\n",
        "\n",
        "print(\" RAGService initialized\")\n",
        "print(f\" Retrieval: top-{TOP_K_RESULTS} documents\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Query: Tell me about Nawaloka's cardiology services and health check packages.\n",
            "\n",
            "================================================================================\n",
            "GENERATING ANSWER WITH RAG SERVICE...\n",
            "================================================================================\n",
            "\n",
            "  Generation time: 6.97s\n",
            " Documents used: 4\n",
            "\n",
            "================================================================================\n",
            "ANSWER\n",
            "================================================================================\n",
            "1. **Key Facts**:\n",
            "   - Nawaloka Hospital offers a broad scope of cardiac services, including advanced diagnostic tools and a dedicated cardiac emergency unit open 24/7.\n",
            "   - The hospital employs a collaborative team approach involving cardiologists, cardiac surgeons, and nurses to ensure comprehensive heart health care.\n",
            "   - Patients receive professional and customized care, whether for regular checkups or complex procedures like heart surgery.\n",
            "\n",
            "2. **Answer**: Nawaloka Hospital provides extensive cardiology services, featuring modern technology for accurate diagnosis and treatment, as well as a 24/7 cardiac emergency unit for urgent conditions. The collaborative approach among healthcare professionals ensures comprehensive care tailored to each patient's needs [Source 1][Source 2][Source 4]. However, specific details about health check packages are not available in the provided context.\n",
            "\n",
            "3. **Contact**: For specific questions, please call +94 11 544 4444.\n",
            "\n",
            "================================================================================\n",
            "EVIDENCE URLS\n",
            "================================================================================\n",
            "  - https://www.nawaloka.com/blogs-and-news/best-cardiologist-in-sri-lanka\n"
          ]
        }
      ],
      "source": [
        "#  Generate Answer with RAG Service\n",
        "USER_QUERY = \"Tell me about Nawaloka's cardiology services and health check packages.\"\n",
        "\n",
        "print(f\" Query: {USER_QUERY}\\n\")\n",
        "print(\"=\" * 80)\n",
        "print(\"GENERATING ANSWER WITH RAG SERVICE...\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "result = rag_service.generate(USER_QUERY)\n",
        "\n",
        "print(f\"\\n  Generation time: {result['generation_time']:.2f}s\")\n",
        "print(f\" Documents used: {result['num_docs']}\")\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"ANSWER\")\n",
        "print(\"=\" * 80)\n",
        "print(result['answer'])\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"EVIDENCE URLS\")\n",
        "print(\"=\" * 80)\n",
        "for url in result['evidence_urls']:\n",
        "    print(f\"  - {url}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# 2️ Cache-Augmented Generation (CAG) with Semantic Matching\n",
        "\n",
        "CAG uses lightweight semantic similarity to cache responses:\n",
        "- **FAQs**: Static questions, never expire\n",
        "- **History**: User queries, 24-hour TTL\n",
        "- **Matching**: Cosine similarity (catches paraphrases!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " CAGService initialized (semantic matching)\n",
            " Cache directory: d:\\Courses\\_Zuu Crew\\AI Engineer Essentials\\Programming\\Context Engineering\\data\\cag_cache\n",
            " Cached responses: 0\n",
            " Similarity threshold: 0.9\n",
            " History TTL: 24h\n"
          ]
        }
      ],
      "source": [
        "#  Initialize CAG Service with Semantic Cache\n",
        "CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Create semantic cache (embedder required for similarity matching)\n",
        "cache = CAGCache(\n",
        "    cache_dir=CACHE_DIR,\n",
        "    embedder=embeddings,  # Uses same embeddings as vector store\n",
        "    similarity_threshold=0.90,  # Catches paraphrased questions\n",
        "    history_ttl_hours=24  # History expires after 24 hours\n",
        ")\n",
        "\n",
        "# Create CAG service\n",
        "cag_service = CAGService(\n",
        "    rag_service=rag_service,\n",
        "    cache=cache\n",
        ")\n",
        "\n",
        "print(\" CAGService initialized (semantic matching)\")\n",
        "print(f\" Cache directory: {CACHE_DIR}\")\n",
        "stats = cache.stats()\n",
        "print(f\" Cached responses: {stats['total_cached']}\")\n",
        "print(f\" Similarity threshold: {stats['similarity_threshold']}\")\n",
        "print(f\" History TTL: {stats['history_ttl_hours']}h\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###  Load Known FAQs\n",
        "\n",
        "FAQs are defined in `config/faqs.yaml` and can be:\n",
        "1. **Loaded** into cache (registers questions)\n",
        "2. **Warmed** (generates responses via RAG)\n",
        "\n",
        "Once warmed, FAQs provide **instant responses** for common questions!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Found 22 FAQs in config/faqs.yaml\n",
            "\n",
            " Sample FAQs:\n",
            "   - What are the visiting hours at Nawaloka Hospital?\n",
            "   - What are the opening hours of Nawaloka Hospital?\n",
            "   - Where is Nawaloka Hospital located?\n",
            "   - What is the address of Nawaloka Hospital?\n",
            "   - How do I contact Nawaloka Hospital?\n",
            "   ... and 17 more\n",
            "\n",
            " Loaded 22 new FAQs into cache\n",
            "\n",
            " Tip: Run cag_service.warm_faqs() to pre-generate FAQ responses\n"
          ]
        }
      ],
      "source": [
        "#  Load Known FAQs from Config (Optional)\n",
        "# FAQs are defined in config/faqs.yaml\n",
        "\n",
        "from context_engineering.config import KNOWN_FAQS\n",
        "\n",
        "print(f\" Found {len(KNOWN_FAQS)} FAQs in config/faqs.yaml\")\n",
        "print(\"\\n Sample FAQs:\")\n",
        "for faq in KNOWN_FAQS[:5]:\n",
        "    print(f\"   - {faq}\")\n",
        "print(f\"   ... and {len(KNOWN_FAQS) - 5} more\\n\")\n",
        "\n",
        "# Load FAQs into cache (this just registers them, doesn't generate responses yet)\n",
        "loaded = cag_service.load_faqs(KNOWN_FAQS)\n",
        "print(f\" Loaded {loaded} new FAQs into cache\")\n",
        "\n",
        "# To warm FAQs (generate responses), uncomment:\n",
        "# print(\"\\n Warming FAQs (this may take a few minutes)...\")\n",
        "# cag_service.warm_faqs()\n",
        "\n",
        "print(\"\\n Tip: Run cag_service.warm_faqs() to pre-generate FAQ responses\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " CRAGService initialized\n",
            " Initial retrieval: top-4\n",
            " Corrective retrieval: top-8\n"
          ]
        }
      ],
      "source": [
        "#  Initialize CRAG Service\n",
        "from context_engineering.config import CRAG_EXPANDED_K\n",
        "\n",
        "crag_service = CRAGService(\n",
        "    retriever=retriever,\n",
        "    llm=llm,\n",
        "    initial_k=TOP_K_RESULTS,\n",
        "    expanded_k=CRAG_EXPANDED_K\n",
        ")\n",
        "\n",
        "print(\" CRAGService initialized\")\n",
        "print(f\" Initial retrieval: top-{TOP_K_RESULTS}\")\n",
        "print(f\" Corrective retrieval: top-{CRAG_EXPANDED_K}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "#  Interactive Inference: Ask Your Own Question\n",
        "\n",
        " **IMPORTANT**: Run all cells above first to initialize all services!\n",
        "\n",
        "Run the cell below to ask your own question and get answers from **all 3 RAG systems** side-by-side!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            " INTERACTIVE RAG INFERENCE\n",
            "================================================================================\n",
            "\n",
            " Ask your question about Nawaloka Hospital...\n",
            "\n",
            "\n",
            " Processing query: 'Where is the Navaloka Hospital Located?'\n",
            "\n",
            "================================================================================\n",
            "\n",
            "1  Standard RAG\n",
            "--------------------------------------------------------------------------------\n",
            " Completed in 4.66s\n",
            " Documents retrieved: 8\n",
            "\n",
            " Answer:\n",
            "1. **Key Facts**:\n",
            "   - Nawaloka Hospital is located at No. 23, Deshamanya H K Dharmadasa Mawatha, Colombo 02, Sri Lanka.\n",
            "   - It is one of the first private premium healthcare service providers in Sri Lanka.\n",
            "\n",
            "2. **Answer**: Nawaloka Hospital is situated at No. 23, Deshamanya H K Dharmadasa Mawatha, Colombo 02, Sri Lanka [Source 1][Source 2].\n",
            "\n",
            "3. **Contact**: For specific questions, please call +94 11 544 4444.\n",
            "\n",
            " Evidence URLs:\n",
            "   • https://www.nawaloka.com/international\n",
            "   • https://www.nawaloka.com/\n",
            "   • https://www.nawaloka.com/blogs-and-news/best-cardiologist-in-sri-lanka\n",
            "\n",
            "================================================================================\n",
            "\n",
            "2  Cache-Augmented Generation (CAG)\n",
            "--------------------------------------------------------------------------------\n",
            " Completed in 0.55s\n",
            " Cache hit: True\n",
            " Documents retrieved: 3\n",
            "\n",
            " Answer:\n",
            "1. **Key Facts**:\n",
            "   - Nawaloka Hospitals is located at No. 23, Deshamanya H K Dharmadasa Mawatha, Colombo 02, Sri Lanka.\n",
            "   - The hospital has a bed capacity of 3000+ and offers services to international patients.\n",
            "\n",
            "2. **Answer**: Nawaloka Hospital is situated at No. 23, Deshamanya H K Dharmadasa Mawatha, Colombo 02, Sri Lanka [Source 1][Source 2].\n",
            "\n",
            "3. **Contact**: For specific questions, please call +94 11 544 4444.\n",
            "\n",
            " Evidence URLs:\n",
            "   • https://www.nawaloka.com/international\n",
            "   • https://www.nawaloka.com/blogs-and-news/laparoscopic-surgery-cost-in-sri-lanka\n",
            "   • https://www.nawaloka.com/blogs-and-news/best-cardiologist-in-sri-lanka\n",
            "\n",
            "================================================================================\n",
            "\n",
            "3  Corrective RAG (CRAG)\n",
            "--------------------------------------------------------------------------------\n",
            " Completed in 2.37s\n",
            " Confidence: 0.68\n",
            " Correction applied: True\n",
            " Documents used: 8\n",
            "\n",
            " Answer:\n",
            "1. **Key Facts**:\n",
            "   - Nawaloka Hospital is located at No. 23, Deshamanya H K Dharmadasa Mawatha, Colombo 02, Sri Lanka.\n",
            "   - It is one of the first private premium healthcare service providers in Sri Lanka.\n",
            "\n",
            "2. **Answer**: Nawaloka Hospital is situated at No. 23, Deshamanya H K Dharmadasa Mawatha, Colombo 02, Sri Lanka [Source 1][Source 2].\n",
            "\n",
            "3. **Contact**: For specific questions, please call +94 11 544 4444.\n",
            "\n",
            " Evidence URLs:\n",
            "   • https://www.nawaloka.com/international\n",
            "   • https://www.nawaloka.com/\n",
            "   • https://www.nawaloka.com/blogs-and-news/best-cardiologist-in-sri-lanka\n",
            "\n",
            "================================================================================\n",
            " PERFORMANCE COMPARISON\n",
            "================================================================================\n",
            "\n",
            "System          Time (s)     Docs     Special Feature               \n",
            "--------------------------------------------------------------------------------\n",
            "Standard RAG    4.66         8        Baseline                      \n",
            "CAG             0.55         3        Cache: HIT                    \n",
            "CRAG            2.37         8        Confidence: 0.68 ⚠️           \n",
            "================================================================================\n",
            " RECOMMENDATION\n",
            "================================================================================\n",
            " Fastest: CAG (0.55s)\n",
            " Best Choice: CAG (cache hit = instant response)\n",
            "\n",
            " Inference complete!\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "#  Interactive Inference - Ask Your Own Question\n",
        "\n",
        "# INITIALIZE MISSING SERVICES (fallback if cells weren't run)\n",
        "if 'rag_service' not in dir():\n",
        "    rag_service = RAGService(retriever=retriever, llm=llm, k=TOP_K_RESULTS)\n",
        "if 'cag_service' not in dir():\n",
        "    cache = CAGCache(cache_dir=CACHE_DIR, embedder=embeddings, similarity_threshold=0.90)\n",
        "    cag_service = CAGService(rag_service=rag_service, cache=cache)\n",
        "if 'crag_service' not in dir():\n",
        "    from context_engineering.config import CRAG_EXPANDED_K\n",
        "    crag_service = CRAGService(retriever=retriever, llm=llm, initial_k=TOP_K_RESULTS, expanded_k=CRAG_EXPANDED_K)\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\" INTERACTIVE RAG INFERENCE\")\n",
        "print(\"=\" * 80)\n",
        "print(\"\\n Ask your question about Nawaloka Hospital...\\n\")\n",
        "\n",
        "# Input your question here\n",
        "YOUR_QUESTION = input(\" Your question: \")\n",
        "\n",
        "print(f\"\\n Processing query: '{YOUR_QUESTION}'\\n\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Run through all 3 RAG systems\n",
        "results = {}\n",
        "\n",
        "# 1. Standard RAG\n",
        "print(\"\\n1  Standard RAG\")\n",
        "print(\"-\" * 80)\n",
        "start = time.time()\n",
        "rag_result = rag_service.generate(YOUR_QUESTION)\n",
        "results['RAG'] = {\n",
        "    'answer': rag_result.get('answer', 'N/A'),\n",
        "    'time': rag_result.get('generation_time', rag_result.get('time', 0)),\n",
        "    'docs': rag_result.get('num_docs', len(rag_result.get('evidence_urls', []))),\n",
        "    'urls': rag_result.get('evidence_urls', [])\n",
        "}\n",
        "print(f\" Completed in {results['RAG']['time']:.2f}s\")\n",
        "print(f\" Documents retrieved: {results['RAG']['docs']}\")\n",
        "print(f\"\\n Answer:\")\n",
        "print(results['RAG']['answer'])\n",
        "print(f\"\\n Evidence URLs:\")\n",
        "for url in results['RAG']['urls'][:3]:\n",
        "    print(f\"   • {url}\")\n",
        "\n",
        "# 2. Cache-Augmented Generation\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"\\n2  Cache-Augmented Generation (CAG)\")\n",
        "print(\"-\" * 80)\n",
        "cag_result = cag_service.generate(YOUR_QUESTION, use_cache=True, verbose=False)\n",
        "results['CAG'] = {\n",
        "    'answer': cag_result.get('answer', 'N/A'),\n",
        "    'time': cag_result.get('generation_time', cag_result.get('time', 0)),\n",
        "    'docs': cag_result.get('num_docs', cag_result.get('docs_used', len(cag_result.get('evidence_urls', [])))),\n",
        "    'cache_hit': cag_result.get('cache_hit', False),\n",
        "    'urls': cag_result.get('evidence_urls', [])\n",
        "}\n",
        "print(f\" Completed in {results['CAG']['time']:.2f}s\")\n",
        "print(f\" Cache hit: {results['CAG']['cache_hit']}\")\n",
        "print(f\" Documents retrieved: {results['CAG']['docs']}\")\n",
        "print(f\"\\n Answer:\")\n",
        "print(results['CAG']['answer'])\n",
        "print(f\"\\n Evidence URLs:\")\n",
        "for url in results['CAG']['urls'][:3]:\n",
        "    print(f\"   • {url}\")\n",
        "\n",
        "# 3. Corrective RAG\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"\\n3  Corrective RAG (CRAG)\")\n",
        "print(\"-\" * 80)\n",
        "crag_result = crag_service.generate(YOUR_QUESTION, confidence_threshold=0.6, verbose=False)\n",
        "results['CRAG'] = {\n",
        "    'answer': crag_result.get('answer', 'N/A'),\n",
        "    'time': crag_result.get('generation_time', crag_result.get('time', 0)),\n",
        "    'docs': crag_result.get('docs_used', crag_result.get('num_docs', len(crag_result.get('evidence_urls', [])))),\n",
        "    'confidence': crag_result.get('confidence_final', crag_result.get('confidence', 0.0)),\n",
        "    'corrected': crag_result.get('correction_applied', False),\n",
        "    'urls': crag_result.get('evidence_urls', [])\n",
        "}\n",
        "print(f\" Completed in {results['CRAG']['time']:.2f}s\")\n",
        "print(f\" Confidence: {results['CRAG']['confidence']:.2f}\")\n",
        "print(f\" Correction applied: {results['CRAG']['corrected']}\")\n",
        "print(f\" Documents used: {results['CRAG']['docs']}\")\n",
        "print(f\"\\n Answer:\")\n",
        "print(results['CRAG']['answer'])\n",
        "print(f\"\\n Evidence URLs:\")\n",
        "for url in results['CRAG']['urls'][:3]:\n",
        "    print(f\"   • {url}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\" PERFORMANCE COMPARISON\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"\\n{'System':<15} {'Time (s)':<12} {'Docs':<8} {'Special Feature':<30}\")\n",
        "print(\"-\" * 80)\n",
        "print(f\"{'Standard RAG':<15} {results['RAG']['time']:<12.2f} {results['RAG']['docs']:<8} {'Baseline':<30}\")\n",
        "\n",
        "# CAG feature\n",
        "cag_feature = 'Cache: ' + ('HIT' if results['CAG']['cache_hit'] else 'MISS')\n",
        "print(f\"{'CAG':<15} {results['CAG']['time']:<12.2f} {results['CAG']['docs']:<8} {cag_feature:<30}\")\n",
        "\n",
        "# CRAG feature\n",
        "crag_conf = results['CRAG']['confidence']\n",
        "crag_emoji = ' ✅' if crag_conf > 0.7 else ' ⚠️'\n",
        "crag_feature = f\"Confidence: {crag_conf:.2f}{crag_emoji}\"\n",
        "print(f\"{'CRAG':<15} {results['CRAG']['time']:<12.2f} {results['CRAG']['docs']:<8} {crag_feature:<30}\")\n",
        "\n",
        "# Summary recommendation\n",
        "print(\"=\" * 80)\n",
        "print(\" RECOMMENDATION\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "fastest = min(results.items(), key=lambda x: x[1]['time'])\n",
        "print(f\" Fastest: {fastest[0]} ({fastest[1]['time']:.2f}s)\")\n",
        "\n",
        "if results['CAG']['cache_hit']:\n",
        "    print(\" Best Choice: CAG (cache hit = instant response)\")\n",
        "elif results['CRAG']['confidence'] > 0.7:\n",
        "    print(\" Best Choice: CRAG (high confidence + corrective capability)\")\n",
        "else:\n",
        "    print(\" Best Choice: Standard RAG (reliable baseline)\")\n",
        "\n",
        "print(\"\\n Inference complete!\")\n",
        "print(\"=\" * 80)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "CAG PERFORMANCE TEST\n",
            "================================================================================\n",
            "\n",
            "1  FIRST RUN (Populating cache)...\n",
            "\n",
            "   Query: What are the visiting hours at Nawaloka?...\n",
            "   Time: 3.36s | Cache: False\n",
            "\n",
            "   Query: How do I contact Nawaloka Hospital?...\n",
            "   Time: 4.30s | Cache: False\n",
            "\n",
            "   Query: What services does Nawaloka provide?...\n",
            "   Time: 3.35s | Cache: False\n",
            "\n",
            "\n",
            "2  SECOND RUN (Using cache)...\n",
            "\n",
            "   Query: What are the visiting hours at Nawaloka?...\n",
            "   Time: 0.71s | Cache: True\n",
            "    INSTANT response from cache!\n",
            "\n",
            "   Query: How do I contact Nawaloka Hospital?...\n",
            "   Time: 0.57s | Cache: True\n",
            "    INSTANT response from cache!\n",
            "\n",
            "   Query: What services does Nawaloka provide?...\n",
            "   Time: 0.77s | Cache: True\n",
            "    INSTANT response from cache!\n",
            "\n",
            "\n",
            " Cache Statistics:\n",
            "   Total cached: 26\n",
            "   Cache size: 630.33 KB\n"
          ]
        }
      ],
      "source": [
        "#  Test CAG Performance\n",
        "print(\"=\" * 80)\n",
        "print(\"CAG PERFORMANCE TEST\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "test_queries = [\n",
        "    \"What are the visiting hours at Nawaloka?\",\n",
        "    \"How do I contact Nawaloka Hospital?\",\n",
        "    \"What services does Nawaloka provide?\"\n",
        "]\n",
        "\n",
        "# First run: populate cache\n",
        "print(\"\\n1  FIRST RUN (Populating cache)...\\n\")\n",
        "for query in test_queries:\n",
        "    result = cag_service.generate(query, use_cache=True, verbose=False)\n",
        "    print(f\"   Query: {query[:50]}...\")\n",
        "    print(f\"   Time: {result['generation_time']:.2f}s | Cache: {result['cache_hit']}\")\n",
        "    print()\n",
        "\n",
        "# Second run: cache hits\n",
        "print(\"\\n2  SECOND RUN (Using cache)...\\n\")\n",
        "for query in test_queries:\n",
        "    result = cag_service.generate(query, use_cache=True, verbose=False)\n",
        "    print(f\"   Query: {query[:50]}...\")\n",
        "    print(f\"   Time: {result['generation_time']:.2f}s | Cache: {result['cache_hit']}\")\n",
        "    if result['cache_hit']:\n",
        "        print(f\"    INSTANT response from cache!\")\n",
        "    print()\n",
        "\n",
        "print(\"\\n Cache Statistics:\")\n",
        "stats = cache.stats()\n",
        "print(f\"   Total cached: {stats['total_cached']}\")\n",
        "print(f\"   Cache size: {stats['cache_size_kb']:.2f} KB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "#  Test CRAG with Different Query Types"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "CORRECTIVE RAG (CRAG) TEST\n",
            "================================================================================\n",
            "\n",
            "Test 1/2: Vague query (should trigger correction)\n",
            "--------------------------------------------------------------------------------\n",
            " Query: cardiology\n",
            " Confidence threshold: 0.6\n",
            "\n",
            "  Initial retrieval (k=4)...\n",
            "    Confidence: 0.74\n",
            "    Confidence sufficient - proceeding with initial retrieval\n",
            "\\  Generating answer...\n",
            "\n",
            " Result:\n",
            "   Initial confidence: 0.74\n",
            "   Final confidence: 0.74\n",
            "   Correction applied: False\n",
            "   Documents used: 4\n",
            "   Generation time: 2.03s\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Test 2/2: Specific query (should be confident)\n",
            "--------------------------------------------------------------------------------\n",
            " Query: What are Nawaloka Hospital's cardiology services and facilities?\n",
            " Confidence threshold: 0.6\n",
            "\n",
            "  Initial retrieval (k=4)...\n",
            "    Confidence: 0.73\n",
            "    Confidence sufficient - proceeding with initial retrieval\n",
            "\\  Generating answer...\n",
            "\n",
            " Result:\n",
            "   Initial confidence: 0.73\n",
            "   Final confidence: 0.73\n",
            "   Correction applied: False\n",
            "   Documents used: 4\n",
            "   Generation time: 2.47s\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "#  Test CRAG with Different Query Types\n",
        "print(\"=\" * 80)\n",
        "print(\"CORRECTIVE RAG (CRAG) TEST\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "test_cases = [\n",
        "    {\n",
        "        'query': \"cardiology\",\n",
        "        'label': \"Vague query (should trigger correction)\"\n",
        "    },\n",
        "    {\n",
        "        'query': \"What are Nawaloka Hospital's cardiology services and facilities?\",\n",
        "        'label': \"Specific query (should be confident)\"\n",
        "    }\n",
        "]\n",
        "\n",
        "for i, test in enumerate(test_cases, 1):\n",
        "    print(f\"\\nTest {i}/{len(test_cases)}: {test['label']}\")\n",
        "    print(\"-\" * 80)\n",
        "    \n",
        "    result = crag_service.generate(test['query'], confidence_threshold=0.6)\n",
        "    \n",
        "    print(f\"\\n Result:\")\n",
        "    print(f\"   Initial confidence: {result['confidence_initial']:.2f}\")\n",
        "    print(f\"   Final confidence: {result['confidence_final']:.2f}\")\n",
        "    print(f\"   Correction applied: {result['correction_applied']}\")\n",
        "    print(f\"   Documents used: {result['docs_used']}\")\n",
        "    print(f\"   Generation time: {result['generation_time']:.2f}s\")\n",
        "    print(\"\\n\" + \"-\" * 80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Checking if all services are initialized...\n",
            "\n",
            " RAGService: Ready\n",
            " CAGService: Ready\n",
            " CRAGService: Ready\n",
            " Vector Store: Connected\n",
            "\n",
            "================================================================================\n",
            " All services ready! You can run the remaining cells.\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "#  Check All Services Ready\n",
        "print(\" Checking if all services are initialized...\\n\")\n",
        "\n",
        "services_ready = True\n",
        "\n",
        "# Check RAGService\n",
        "try:\n",
        "    rag_service\n",
        "    print(\" RAGService: Ready\")\n",
        "except NameError:\n",
        "    print(\" RAGService: NOT initialized\")\n",
        "    services_ready = False\n",
        "\n",
        "# Check CAGService\n",
        "try:\n",
        "    cag_service\n",
        "    print(\" CAGService: Ready\")\n",
        "except NameError:\n",
        "    print(\" CAGService: NOT initialized\")\n",
        "    services_ready = False\n",
        "\n",
        "# Check CRAGService\n",
        "try:\n",
        "    crag_service\n",
        "    print(\" CRAGService: Ready\")\n",
        "except NameError:\n",
        "    print(\" CRAGService: NOT initialized\")\n",
        "    services_ready = False\n",
        "\n",
        "# Check Vector Store\n",
        "try:\n",
        "    vectorstore\n",
        "    print(\" Vector Store: Connected\")\n",
        "except NameError:\n",
        "    print(\" Vector Store: NOT connected\")\n",
        "    services_ready = False\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "if services_ready:\n",
        "    print(\" All services ready! You can run the remaining cells.\")\n",
        "else:\n",
        "    print(\"  Some services are missing. Please run all cells above first.\")\n",
        "print(\"=\" * 80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "#  Comprehensive Comparison: RAG vs CAG vs CRAG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            " RAG vs CAG vs CRAG COMPARISON\n",
            "================================================================================\n",
            "\n",
            "1  Standard RAG...\n",
            "     Time: 4.70s\n",
            "\n",
            "2  Cache-Augmented Generation (CAG)...\n",
            "     Time: 4.24s\n",
            "    Cache hit: False\n",
            "\n",
            "3  Corrective RAG (CRAG)...\n",
            "     Time: 3.19s\n",
            "    Correction: False\n",
            "\n",
            "================================================================================\n",
            "COMPARISON TABLE\n",
            "================================================================================\n",
            "   Technique Latency (s)  Docs Retrieved Cache Used Self-Correcting                  Best For\n",
            "Standard RAG        4.70               4         No              No           General queries\n",
            "         CAG        4.24               4         No              No          Frequent queries\n",
            "        CRAG        3.19               4         No             Yes Complex/uncertain queries\n",
            "\n",
            "================================================================================\n",
            "KEY INSIGHTS\n",
            "================================================================================\n",
            " RAG: Baseline - reliable for general queries\n",
            " CAG: Fastest when cache hits - ideal for FAQs\n",
            " CRAG: Most accurate - self-corrects weak evidence\n",
            " HYBRID: Combine all three for production!\n",
            "\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "#  Comprehensive Comparison\n",
        "import pandas as pd\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\" RAG vs CAG vs CRAG COMPARISON\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# comparison_query = \"What cardiology services are available at Nawaloka?\"\n",
        "comparison_query = \"What cardiology services are available at Nawaloka?\"\n",
        "\n",
        "# Test 1: Standard RAG\n",
        "print(f\"\\n1  Standard RAG...\")\n",
        "rag_result = rag_service.generate(comparison_query)\n",
        "print(f\"     Time: {rag_result['generation_time']:.2f}s\")\n",
        "\n",
        "# Test 2: CAG (should use cache on second run)\n",
        "print(f\"\\n2  Cache-Augmented Generation (CAG)...\")\n",
        "cag_result = cag_service.generate(comparison_query, use_cache=True, verbose=False)\n",
        "print(f\"     Time: {cag_result['generation_time']:.2f}s\")\n",
        "print(f\"    Cache hit: {cag_result['cache_hit']}\")\n",
        "\n",
        "# Test 3: CRAG\n",
        "print(f\"\\n3  Corrective RAG (CRAG)...\")\n",
        "crag_result = crag_service.generate(comparison_query, confidence_threshold=0.6, verbose=False)\n",
        "print(f\"     Time: {crag_result['generation_time']:.2f}s\")\n",
        "print(f\"    Correction: {crag_result['correction_applied']}\")\n",
        "\n",
        "# Create comparison table\n",
        "comparison_data = [\n",
        "    {\n",
        "        'Technique': 'Standard RAG',\n",
        "        'Latency (s)': f\"{rag_result['generation_time']:.2f}\",\n",
        "        'Docs Retrieved': rag_result['num_docs'],\n",
        "        'Cache Used': 'No',\n",
        "        'Self-Correcting': 'No',\n",
        "        'Best For': 'General queries'\n",
        "    },\n",
        "    {\n",
        "        'Technique': 'CAG',\n",
        "        'Latency (s)': f\"{cag_result['generation_time']:.2f}\",\n",
        "        'Docs Retrieved': 'Cached' if cag_result['cache_hit'] else rag_result['num_docs'],\n",
        "        'Cache Used': 'Yes' if cag_result['cache_hit'] else 'No',\n",
        "        'Self-Correcting': 'No',\n",
        "        'Best For': 'Frequent queries'\n",
        "    },\n",
        "    {\n",
        "        'Technique': 'CRAG',\n",
        "        'Latency (s)': f\"{crag_result['generation_time']:.2f}\",\n",
        "        'Docs Retrieved': crag_result['docs_used'],\n",
        "        'Cache Used': 'No',\n",
        "        'Self-Correcting': 'Yes',\n",
        "        'Best For': 'Complex/uncertain queries'\n",
        "    }\n",
        "]\n",
        "\n",
        "df = pd.DataFrame(comparison_data)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"COMPARISON TABLE\")\n",
        "print(\"=\" * 80)\n",
        "print(df.to_string(index=False))\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"KEY INSIGHTS\")\n",
        "print(\"=\" * 80)\n",
        "print(\" RAG: Baseline - reliable for general queries\")\n",
        "print(\" CAG: Fastest when cache hits - ideal for FAQs\")\n",
        "print(\" CRAG: Most accurate - self-corrects weak evidence\")\n",
        "print(\" HYBRID: Combine all three for production!\")\n",
        "print(\"\\n\" + \"=\" * 80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "#  Summary\n",
        "\n",
        "All three RAG techniques implemented using service layer:\n",
        "-  **RAGService**: Standard RAG with modern LCEL\n",
        "-  **CAGService**: Cache-augmented generation with semantic matching\n",
        "-  **CRAGService**: Corrective RAG with confidence scoring\n",
        "\n",
        "**CAG Semantic Caching**:\n",
        "-  **Catches paraphrases**: \"What are visiting hours?\" matches \"Tell me the visiting hours\"\n",
        "-  **Two-tier**: Static FAQs (never expire) + Dynamic History (24h TTL)\n",
        "-  **Lightweight**: Only new queries need embedding, cached ones use stored embeddings\n",
        "-  **Fast lookup**: Cosine similarity is just a dot product (~1ms for 1000 entries)\n",
        "\n",
        "**Benefits of service-based architecture**:\n",
        "-  Reusable across notebooks and production code\n",
        "-  Easily testable\n",
        "-  Well-documented\n",
        "-  Maintainable (logic in one place)\n",
        "\n",
        "**OpenRouter Multi-Provider Support**:\n",
        "-  One API key → access to OpenAI, Anthropic, Google, Meta, DeepSeek\n",
        "-  Configure models in `config/models.yaml`\n",
        "-  Switch providers without code changes"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "sahas",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
